{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Download the dataset and import needed functions for part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kagglehub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkagglehub\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Download latest version\u001b[39;00m\n\u001b[1;32m      4\u001b[0m path \u001b[38;5;241m=\u001b[39m kagglehub\u001b[38;5;241m.\u001b[39mdataset_download(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrouplens/movielens-20m-dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kagglehub'"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"grouplens/movielens-20m-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import random\n",
    "from sympy import isprime\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strong> 1. Recommendation System with LSH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strong> 1.1 Data Preparation\n",
    "Download the MovieLens dataset from here. After downloading, explore the dataset to understand the structure and identify any preprocessing steps needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> There are in total 6 datasets, let's have a quick look at them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tagId</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.02500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.02500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.05775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tagId  relevance\n",
       "movieId                  \n",
       "1            1    0.02500\n",
       "1            2    0.02500\n",
       "1            3    0.05775"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome_scores = pd.read_csv(\"dataset/genome_scores.csv\", index_col =0)\n",
    "genome_scores.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tagId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>007 (series)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18th century</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tag\n",
       "tagId              \n",
       "1               007\n",
       "2      007 (series)\n",
       "3      18th century"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome_tags = pd.read_csv(\"dataset/genome_tags.csv\", index_col = 0)\n",
    "genome_tags.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdbId</th>\n",
       "      <th>tmdbId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114709</td>\n",
       "      <td>862.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113497</td>\n",
       "      <td>8844.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113228</td>\n",
       "      <td>15602.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         imdbId   tmdbId\n",
       "movieId                 \n",
       "1        114709    862.0\n",
       "2        113497   8844.0\n",
       "3        113228  15602.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = pd.read_csv(\"dataset/link.csv\", index_col = 0)\n",
    "link.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title                                       genres\n",
       "movieId                                                                      \n",
       "1               Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy\n",
       "2                 Jumanji (1995)                   Adventure|Children|Fantasy\n",
       "3        Grumpier Old Men (1995)                               Comedy|Romance"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie = pd.read_csv(\"dataset/movie.csv\", index_col = 0)\n",
    "movie.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:53:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:31:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:33:39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating            timestamp\n",
       "0       1        2     3.5  2005-04-02 23:53:47\n",
       "1       1       29     3.5  2005-04-02 23:31:16\n",
       "2       1       32     3.5  2005-04-02 23:33:39"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = pd.read_csv(\"dataset/rating.csv\")\n",
    "rating.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4141</td>\n",
       "      <td>Mark Waters</td>\n",
       "      <td>2009-04-24 18:19:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>208</td>\n",
       "      <td>dark hero</td>\n",
       "      <td>2013-05-10 01:41:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>353</td>\n",
       "      <td>dark hero</td>\n",
       "      <td>2013-05-10 01:41:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        movieId          tag            timestamp\n",
       "userId                                           \n",
       "18         4141  Mark Waters  2009-04-24 18:19:40\n",
       "65          208    dark hero  2013-05-10 01:41:18\n",
       "65          353    dark hero  2013-05-10 01:41:19"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag = pd.read_csv(\"dataset/tag.csv\", index_col = 0)\n",
    "tag.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66895/1612435243.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  user_ratings = rating.groupby('userId').apply(\n"
     ]
    }
   ],
   "source": [
    "# Map movie names into ratings_df\n",
    "rating= rating.merge(movie, on='movieId')\n",
    "\n",
    "# Create user_movies dictionary\n",
    "user_movies = rating.groupby('userId')['movieId'].apply(list).to_dict()\n",
    "\n",
    "# Create user_ratings dictionary\n",
    "user_ratings = rating.groupby('userId').apply(\n",
    "    lambda group: dict(zip(group['movieId'], group['rating']))\n",
    ").to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <strong>1.2 Minhash Signatures</strong>\n",
    "\n",
    "Using the userId and movieId columns, implement your own MinHash function. This function will hash each user's watched movie list, creating a representation that allows for quick comparisons of user similarities.\n",
    "\n",
    "    -Important: Implement your MinHash function from scratch—do not use any pre-built hash functions.\n",
    "    -Use your MinHash function to generate signature vectors for each user based on their rated movies.\n",
    "    -Experiment with different hash functions and threshold values to find the most effective configurations. Report these results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first group all the users and their correspective movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_movies = rating.groupby('userId')['movieId'].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a simple modulo hash function: <br> <br>\n",
    "$\n",
    "h(x) = (a \\cdot x + b) \\mod p\n",
    "$\n",
    "\n",
    "Where:  \n",
    "- $ x $: Input value  \n",
    "- $ a $: Coefficient (non-zero)  \n",
    "- $ b $: Coefficient  \n",
    "- $ p $: Prime modulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_function(x, a ,b ,p): \n",
    "    return (a*x + b) % p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate multiple hash functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hash_functions(max_value, max_prime):\n",
    "    \n",
    "    primes = [i for i in range(10,max_prime) if isprime(i)]\n",
    "\n",
    "    # Generate multiple hash functions\n",
    "    hash_functions = []\n",
    "    for i in range(10):\n",
    "        a = random.randint(1, max_value)  # Random coefficient a (non-zero)\n",
    "        b = random.randint(0, max_value)  # Random coefficient b\n",
    "        p = random.choice(primes)  # Predefined prime values\n",
    "        \n",
    "        hash_functions.append(lambda x, a=a, b=b, p=p: hash_function(x, a, b, p))\n",
    "    return hash_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now given these hash functions, we create our signature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minhash(user_movies, hash_functions):\n",
    "    signature_matrix = {}\n",
    "\n",
    "    for user, movies in user_movies.items():\n",
    "        signature_vector = []\n",
    "        for h in hash_functions:\n",
    "            min_hash = min(h(movie) for movie in movies)  # Compute min hash value for the user's movies\n",
    "            signature_vector.append(min_hash)\n",
    "        signature_matrix[user] = signature_vector\n",
    "    \n",
    "    return signature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_signatures = minhash(user_movies,create_hash_functions(max_value = 10000, max_prime = 1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Effectiveness of the Hashing Function**\n",
    "\n",
    "To evaluate the effectiveness of our MinHash function, we compare the **Jaccard similarity** of two sets with the **MinHash similarity** of their corresponding signature matrices. We then calculate the error using the squared Euclidean distance between the two similarities.\n",
    "\n",
    "#### 1. **Jaccard Similarity**\n",
    "\n",
    "The Jaccard similarity between two sets $A $ and $B $ is defined as:\n",
    "\n",
    "$\n",
    "J(A, B) = \\frac{|A \\cap B|}{|A \\cup B|}\n",
    "$\n",
    "\n",
    "#### 2. **MinHash Similarity**\n",
    "\n",
    "The MinHash similarity between two signature vectors $\\text{sig}_1 $ and $\\text{sig}_2 $ is given by:\n",
    "\n",
    "$\n",
    "\\text{MinHashSim}(\\text{sig}_1, \\text{sig}_2) = \\frac{\\text{Number of Matching Hashes}}{\\text{Total Number of Hashes}}\n",
    "$\n",
    "\n",
    "$\n",
    "\\text{MinHashSim}(\\text{sig}_1, \\text{sig}_2) = \\frac{\\sum_{i=1}^n \\mathbb{1}(\\text{sig}_1[i] = \\text{sig}_2[i])}{n}\n",
    "$\n",
    "\n",
    "where $\\mathbb{1} $ is the indicator function that returns $1 $ if the elements are equal and $0 $ otherwise.\n",
    "\n",
    "#### 3. **Error Calculation**\n",
    "\n",
    "The error is computed as the squared Euclidean distance between the true Jaccard similarity and the MinHash similarity:\n",
    "\n",
    "$\n",
    "\\text{Error} = (J(A, B) - \\text{MinHashSim}(\\text{sig}_1, \\text{sig}_2))^2\n",
    "$\n",
    "\n",
    "#### 4. **Total Error Across Users**\n",
    "\n",
    "For all pairs of users \\((u_1, u_2)$, the total error is computed as:\n",
    "\n",
    "$\n",
    "\\text{Total Error} = \\frac{\\sum_{(u_1, u_2) \\in \\text{Users}} \\text{Error}(u_1, u_2)}{|\\text{Users}|^2}\n",
    "$\n",
    "\n",
    "Where:\n",
    "- $\\text{Users} $ is the set of all user pairs.\n",
    "- $\\text{Error}(u_1, u_2) $ is the squared Euclidean error for a pair of users.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity we only ran 10000 lines including 90 users\n",
    "\n",
    "# True Jaccard similarity\n",
    "def jaccard_similarity(set1, set2):\n",
    "    return len(set1.intersection(set2)) / len(set1.union(set2))\n",
    "\n",
    "# MinHash similarity\n",
    "def minhash_similarity(sig1, sig2):\n",
    "    return sum(1 for a, b in zip(sig1, sig2) if a == b) / len(sig1)\n",
    "\n",
    "# Evaluate effectiveness\n",
    "def evaluate_effectiveness(user_movies, signature_matrix):\n",
    "    users = list(user_movies.keys())\n",
    "\n",
    "    tot_error = 0\n",
    "    for user1, user2 in combinations(users, 2):\n",
    "        set1, set2 = set(user_movies[user1]), set(user_movies[user2])\n",
    "        sig1, sig2 = signature_matrix[user1], signature_matrix[user2]\n",
    "        \n",
    "        # Compute similarities\n",
    "        true_jaccard = jaccard_similarity(set1, set2)\n",
    "        approx_minhash = minhash_similarity(sig1, sig2)\n",
    "        \n",
    "        # Calculate Error\n",
    "        error = (true_jaccard - approx_minhash)**2\n",
    "        tot_error += error\n",
    "    \n",
    "    return tot_error / (len(users)**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our results given different types of values for the hashing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "parameters = []\n",
    "for i in range(10,1000,5):\n",
    "    parameters.append(i)\n",
    "    hash_functions = create_hash_functions(i, i*2)\n",
    "    signature_matrix = minhash(user_movies,hash_functions)\n",
    "    result = evaluate_effectiveness(user_movies,signature_matrix)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 8))  \n",
    "plt.scatter(parameters, results, color='pink', label='average error',alpha = 0.9)  # Plot points\n",
    "plt.title(\"Relationship between parameter and results\")  \n",
    "plt.xlabel(\"Parameter\") \n",
    "plt.ylabel(\"Average Error\") \n",
    "plt.legend() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see a direct relationship between the maximum value in the hashing function and the error. As the maximum value grows, the likelihood of hash collisions decreases, resulting in a better approximation of the true Jaccard similarity and a reduction in error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strong> 1.3 Locality-Sensitive Hashing (LSH) </strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong> 1.3.1 Bucket Creation: For each user, divide the MinHash signature into bands and hash each band to form buckets. Users with similar bands should fall into the same buckets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a custom hashing function for buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_bucket_hash(sig):\n",
    "    return sum(sig) % 1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsh(minhash_signatures, num_bands):\n",
    "    \"\"\"\n",
    "    Locality-Sensitive Hashing (LSH) for clustering similar users.\n",
    "\n",
    "    Args:\n",
    "        minhash_signatures (dict): Dictionary mapping user IDs to their MinHash signatures.\n",
    "        num_bands (int): Number of bands to divide the signature into.\n",
    "\n",
    "    Returns:\n",
    "        buckets (defaultdict): Mapping from bucket keys to sets of user IDs.\n",
    "    \"\"\"\n",
    "    # Initialize buckets\n",
    "    buckets = defaultdict(set)\n",
    "    num_rows = len(next(iter(minhash_signatures.values()))) // num_bands  # Rows per band\n",
    "\n",
    "    # Create buckets for each band\n",
    "    for user, signature in minhash_signatures.items():\n",
    "        for band_idx in range(num_bands):\n",
    "            # Extract rows for the current band\n",
    "            start = band_idx * num_rows\n",
    "            end = start + num_rows\n",
    "            band = tuple(signature[start:end])  # Ensure immutability for hashing\n",
    "            # Hash the band and add the user to the corresponding bucket\n",
    "            bucket_key = custom_bucket_hash(band)\n",
    "            buckets[bucket_key].add(user)\n",
    "    \n",
    "    return buckets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong>  1.3.2 Query: For a given user, identify the two most similar users based on their bucket placement. If a user doesn’t have any similar users in their bucket, adjust the parameters until similar users are found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_similar_users(user, minhash_signatures, buckets):\n",
    "    \"\"\"\n",
    "    Query the most similar users for a given user using LSH buckets.\n",
    "\n",
    "    Args:\n",
    "        user (str): User ID for whom to find similar users.\n",
    "        minhash_signatures (dict): MinHash signatures for all users.\n",
    "        buckets (defaultdict): Buckets created using LSH.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, float]]: Two most similar users and their MinHash similarity scores.\n",
    "    \"\"\"\n",
    "    user_signature = minhash_signatures[user]\n",
    "    similar_users = set()\n",
    "\n",
    "    # Find all buckets containing the given user\n",
    "    for bucket_users in buckets.values():\n",
    "        if user in bucket_users:\n",
    "            similar_users.update(bucket_users)\n",
    "    \n",
    "    # Remove the queried user from the set of similar users\n",
    "    similar_users.discard(user)\n",
    "\n",
    "    # Compute MinHash similarities\n",
    "    similarities = [\n",
    "        (other_user, minhash_similarity(user_signature, minhash_signatures[other_user]))\n",
    "        for other_user in similar_users\n",
    "    ]\n",
    "\n",
    "    # Sort by similarity in descending order and return the top two\n",
    "    return sorted(similarities, key=lambda x: x[1], reverse=True)[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar users for 'user1': [(41059, 0.4), (84182, 0.4)]\n"
     ]
    }
   ],
   "source": [
    "# Apply LSH\n",
    "num_bands = 3  # Choose the number of bands\n",
    "buckets = lsh(user_signatures, num_bands)\n",
    "\n",
    "\n",
    "# Query similar users for \"user1\"\n",
    "similar_users = query_similar_users(1, user_signatures, buckets)\n",
    "print(f\"Similar users for 'user1': {similar_users}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong> 1.3.3 Movie Recommendation Logic: </strong>\n",
    "\n",
    "    If both similar users have rated a movie, recommend this movie based on the average rating.\n",
    "    If there are no commonly rated movies, recommend the top-rated movies of the most similar user.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies(target_user, user_movies, user_ratings, similar_users, max_recommendations=5):\n",
    "    \"\"\"\n",
    "    Recommends movies for a target user based on similar users' ratings.\n",
    "\n",
    "    Args:\n",
    "        target_user (str): The user for whom recommendations are generated.\n",
    "        user_movies (dict): Movies watched by each user.\n",
    "        user_ratings (dict): Ratings given by each user for movies.\n",
    "        similar_users (list): Two most similar users (in descending similarity order).\n",
    "        max_recommendations (int): Maximum number of recommendations.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, float]]: Recommended movies and their ratings.\n",
    "    \"\"\"\n",
    "    # Movies rated by the target user\n",
    "    target_user_movies = set(user_movies[target_user])\n",
    "    \n",
    "    # Movies rated by similar users\n",
    "    similar_user_1, similar_user_2 = similar_users\n",
    "    user1_movies = set(user_movies[similar_user_1])\n",
    "    user2_movies = set(user_movies[similar_user_2])\n",
    "\n",
    "    # Find common movies and compute average ratings\n",
    "    common_movies = user1_movies & user2_movies\n",
    "    recommendations = []\n",
    "    for movie in common_movies:\n",
    "        movie1 = user_ratings[similar_user_1][movie]\n",
    "        movie2 = user_ratings[similar_user_2][movie]\n",
    "        avg_rating = (movie1 + movie2) / 2\n",
    "        recommendations.append((movie, avg_rating))\n",
    "\n",
    "    # Sort recommendations by average rating\n",
    "    recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Add top-rated movies from the most similar user\n",
    "    most_similar_user = similar_user_1\n",
    "    for movie, rating in sorted(user_ratings[most_similar_user].items(), key=lambda x: x[1], reverse=True):\n",
    "        if len(recommendations) >= max_recommendations:\n",
    "            break\n",
    "        if movie not in target_user_movies and movie not in [rec[0] for rec in recommendations]:\n",
    "            recommendations.append((movie, rating))\n",
    "    \n",
    "    # Fill up to 5 recommendations using the second most similar user if needed\n",
    "    if len(recommendations) < max_recommendations:\n",
    "        for movie, rating in sorted(user_ratings[similar_user_2].items(), key=lambda x: x[1], reverse=True):\n",
    "            if len(recommendations) >= max_recommendations:\n",
    "                break\n",
    "            if movie not in target_user_movies and movie not in [rec[0] for rec in recommendations]:\n",
    "                recommendations.append((movie, rating))\n",
    "    \n",
    "    return recommendations[:max_recommendations]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 1\n",
    "similar_users = [user for user, score in query_similar_users(target,user_signatures,buckets)]\n",
    "recommendations = recommend_movies(target_user=1, \n",
    "                                   user_movies=user_movies, \n",
    "                                   user_ratings=user_ratings, \n",
    "                                   similar_users=similar_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong> 1.3.4 Final Recommendation: Provide at most five movies to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Full Metal Jacket (1987)</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Matrix, The (1999)</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alien (1979)</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Truman Show, The (1998)</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Highlander (1986)</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title  score\n",
       "0  Full Metal Jacket (1987)    4.5\n",
       "1        Matrix, The (1999)    4.5\n",
       "2              Alien (1979)    4.5\n",
       "3   Truman Show, The (1998)    4.5\n",
       "4         Highlander (1986)    4.5"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations_df = pd.DataFrame(recommendations, columns=['movieId', 'score'])\n",
    "result_df = recommendations_df.merge(movie, on='movieId', how='left')\n",
    "result_df[['title', 'score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from kmeans import *\n",
    "dataframes = {}\n",
    "for dataset in os.listdir(path): # list all files in the directory\n",
    "    print(dataset)\n",
    "    dataframes[dataset] = pd.read_csv(os.path.join(path, dataset)) # load the dataset into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in dataframes:\n",
    "    print(dataset)\n",
    "    print(f\"Shape: {dataframes[dataset].shape}\")\n",
    "    print(dataframes[dataset].head(3))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_df = dataframes['tag.csv']\n",
    "movies_df = dataframes['movie.csv']\n",
    "ratings_df = dataframes['rating.csv']\n",
    "links_df = dataframes['link.csv']\n",
    "genome_scores_df = dataframes['genome_scores.csv']\n",
    "genome_tags_df = dataframes['genome_tags.csv']\n",
    "\n",
    "print(movies_df.info()); print(f\"Are the movie id's unique? {movies_df.movieId.nunique() == movies_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Grouping Movies Together!\n",
    "\n",
    "In this section, you will explore clustering algorithms to group the movies you have based on specific features you choose to consider for them.\n",
    "\n",
    "### 2.1 Feature Engineering\n",
    "\n",
    "As you know, the dataset provided isn't particularly clean or well-structured to represent the features of the movies. Therefore, your first step is to create a more suitable set of attributes (variables, features, covariates) to represent the movies based on the available information. Here are some variables or features you might consider for clustering:\n",
    "\n",
    "1. **movieid**: id of each movie\n",
    "2. **genres**: list of genres attached to the movie (given that a movie may have several genres, it's essential to devise a method to accurately represent the genres for each movie)\n",
    "3. **ratings_avg**: the average ratings provided by users for the movie\n",
    "4. **relevant_genome_tag**: the most relevant tag to the movie given in the genome set\n",
    "5. **common_user_tag**: the most common tag given to the movie by the users\n",
    "\n",
    "In addition to the above features, include at least three additional features for clustering.\n",
    "\n",
    "Note: If you have accurately identified and applied the methods for representing the features, you should have more than eight features!\n",
    "How could this happen? Take a moment to think about it.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping in mind that we are preparing the dataset for *movies* and that we will be clustering movies later on! I will keep the movie id column as it is and will start by using the movies dataset to make one hot encoding for genres and represent the genres for each movieid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some field in the genres column contain values such as (no genres listed). We can see that the total number of such values are 246:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of Values containing \"(no genres listed)\" are: {movies_df['genres'].str.contains('no').sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now because our movies dataset have over 27000 movies, we can safely drop such rows!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace these with None\n",
    "movies_df['genres'] = movies_df['genres'].apply(lambda x: x if x != '(no genres listed)' else None)\n",
    "\n",
    "# dropping such rows\n",
    "movies_df.dropna(subset=['genres'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1: One-hot encode genres\n",
    "movies_df[\"genres\"] = movies_df[\"genres\"].str.split(\"|\")\n",
    "genre_list = set(g for genres in movies_df[\"genres\"] for g in genres)\n",
    "for genre in genre_list:\n",
    "    movies_df[genre] = movies_df[\"genres\"].apply(lambda x: 1 if genre in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.head(3)\n",
    "\n",
    "movies_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, going to the the second feature, I will use the ratings dataset to calculate average ratings for each movieid and merge it with the original movies dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ratings_df.shape)\n",
    "ratings_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 2: Average rating\n",
    "rating_avg = ratings_df.groupby(\"movieId\")[\"rating\"].mean().rename(\"ratings_avg\")\n",
    "rating_avg.head(3)\n",
    "\n",
    "rating_avg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the movies datframe and the rating_avg series are different. It means that there are some movie ids for which no ratings are given. Because our ultimate task is to cluster movies based on some particular features, we will only keep the movie ids for which there are ratings, i.e. by performing an *inner join*. We will adapt the same strategy for other features as well. However, I would like to *emphasize* that this strategy will greatly reduce the size of the movies set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = movies_df.merge(rating_avg, on=\"movieId\")\n",
    "movies_df.head(3)\n",
    "\n",
    "movies_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3: Common user tags\n",
    "top_10_common_tags = tags_df.groupby('movieId')['tag'].apply(list).apply(lambda x: Counter(x).most_common(10))\n",
    "top_10_common_tags.head(3)\n",
    "\n",
    "top_10_common_tags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = movies_df.merge(top_10_common_tags, on='movieId')\n",
    "\n",
    "movies_df.head(3)\n",
    "\n",
    "movies_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will normalize the tag counts into relative frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[\"tag\"] = movies_df[\"tag\"].apply(lambda tags: [(tag, round(count/sum(count for tag, count in tags), 2)) for tag, count in tags])\n",
    "movies_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.rename(columns={'tag': 'top_10_user_defined_tags'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we will be performing PCA and Clustering eventually, the dataset features needs to be numeric in nature. I could have inserted only the first most common user defined tag for each movie, but I inserted 10 most common for the following reason: Use these tags to come up with a metric that show relevance_score_for_tags for each movie id.\n",
    "\n",
    "The `relevance_score_for_tags` for a movie is computed as:\n",
    "\n",
    "$$ \\text{Relevance Score} = \\sum_{t \\in \\text{movie tags}} \\text{Relevance}_t \\cdot \\text{GlobalWeight}_t $$\n",
    "\n",
    "#### Components:\n",
    "\n",
    "1. **Relevance of the Tag** $ \\text{Relevance}_t $:\n",
    "   - Represents how strongly the tag $ t $ is associated with the movie, based on the `relevance` of a tag deried using its relative frequeny which is computed using the frequency each user labelled (tagged) the movie / total tags\n",
    "   - Tags with higher relevance contribute more to the score.\n",
    "\n",
    "2. **Global Weight of the Tag** $ \\text{GlobalWeight}_t $:\n",
    "   - Captures how \"rare\" or \"informative\" the tag $t$ is across all movies. \n",
    "   - Tags that appear in fewer movies have higher weights because they are more distinctive.\n",
    "   - Modeled using:\n",
    "     $$\n",
    "     \\text{GlobalWeight}_t = \\log \\frac{N}{n_t}\n",
    "     $$\n",
    "     Where $N$ is the total number of movies, and $n_t$ is the number of movies containing the tag $t$.\n",
    "\n",
    "\n",
    "\n",
    "### **How to Interpret the Score**\n",
    "1. **High Relevance Score:**\n",
    "   - The movie is strongly associated with its top tags.\n",
    "   - The tags are unique or rare across the dataset, making the movie more distinct.\n",
    "   - Example: A movie with unique tags like \"Mind-Boggling\" or \"Historical\" may have a higher score than one with generic tags like \"Drama\" or \"Comedy.\"\n",
    "\n",
    "2. **Low Relevance Score:**\n",
    "   - The movie is associated with common tags or tags with low relevance.\n",
    "   - The movie might not have a strong identity defined by its tags.\n",
    "   - Example: A movie tagged with common terms like \"Drama\" and \"Action\" might have a lower score than one tagged with niche terms like \"Sci-Fi Thriller.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the list of all tags for all movies\n",
    "all_tags = [tag for tags in movies_df['top_10_user_defined_tags'] for tag, count in tags]\n",
    "\n",
    "# Count occurrences of each tag\n",
    "tag_counts = Counter(all_tags)\n",
    "\n",
    "# Total number of movies\n",
    "total_movies = len(movies_df)\n",
    "\n",
    "# Compute the global weight for each tag (inverse tag frequency)\n",
    "global_weights = {tag: np.log(total_movies / count) for tag, count in tag_counts.items()}\n",
    "\n",
    "def compute_relevance_score(tags, global_weights):\n",
    "    score = 0\n",
    "    for tag, relevance in tags:\n",
    "        global_weight = global_weights.get(tag, 0)\n",
    "        score += relevance * global_weight\n",
    "    return score\n",
    "\n",
    "# Compute the relevance score for each movie\n",
    "movies_df['relevance_score_for_tags'] = movies_df['top_10_user_defined_tags'].apply(\n",
    "    lambda tags: compute_relevance_score(tags, global_weights)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the fourth feature, we will make use of genome tags and their relavance from the `genome_tags` and `genome_scores` dataset, eventually merging them abck to the original movies dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_scores_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_tags_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of unique genome_scores_df for each movie ids are 10381 - further reducing the size of the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_scores_df.movieId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort genome_scores_df by movieId and relevance in descending order\n",
    "sorted_genome_scores_df = genome_scores_df.sort_values(by=['movieId', 'relevance'], ascending=[True, False])\n",
    "\n",
    "# Group by movieId and select the top 10 tags for each movie using groupby().apply()\n",
    "\n",
    "def get_top_tags(group):\n",
    "    return group.head(10)\n",
    "\n",
    "top_10_relevant_tags = sorted_genome_scores_df.groupby('movieId').apply(get_top_tags).reset_index(drop=True)\n",
    "\n",
    "# Merge with genome_tags_df to get the tag names\n",
    "relevant_tags = top_10_relevant_tags.merge(genome_tags_df, on='tagId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_tags.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate tags into a list for each movieId\n",
    "tag_sets = relevant_tags.groupby('movieId').apply(lambda x: list(zip(x['tag'], x['relevance']))).reset_index()\n",
    "tag_sets.columns = ['movieId', 'tag_relevance']\n",
    "# Make movieId the index of the dataframe\n",
    "tag_sets.set_index('movieId', inplace=True)\n",
    "\n",
    "tag_sets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the movie dataset with the tag_sets to add the 10 most relevant genome tags\n",
    "movies_df = movies_df.merge(tag_sets, on=\"movieId\")\n",
    "movies_df.rename(columns={\"tag_relevance\": \"10_most_relevant_genome_tags\"}, inplace=True)\n",
    "# Display the updated dataframe\n",
    "movies_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `relevance_score_for_genome_tags` for a movie is computed as:\n",
    "\n",
    "$$ \\text{Relevance Score} = \\sum_{t \\in \\text{movie tags}} \\text{Relevance}_t \\cdot \\text{GlobalWeight}_t $$\n",
    "\n",
    "#### Components:\n",
    "\n",
    "1. **Relevance of the Tag** $ \\text{Relevance}_t $:\n",
    "   - Represents how strongly the tag $ t $ is associated with the movie, based on the `relevance` field in the genome dataset. \n",
    "   - Tags with higher relevance contribute more to the score.\n",
    "\n",
    "2. **Global Weight of the Tag** $ \\text{GlobalWeight}_t $:\n",
    "   - Captures how \"rare\" or \"informative\" the tag $t$ is across all movies. \n",
    "   - Tags that appear in fewer movies have higher weights because they are more distinctive.\n",
    "   - Modeled using:\n",
    "     $$\n",
    "     \\text{GlobalWeight}_t = \\log \\frac{N}{n_t}\n",
    "     $$\n",
    "     Where $N$ is the total number of movies, and $n_t$ is the number of movies containing the tag $t$.\n",
    "\n",
    "\n",
    "\n",
    "### **How to Interpret the Score**\n",
    "1. **High Relevance Score:**\n",
    "   - The movie is strongly associated with its top tags.\n",
    "   - The tags are unique or rare across the dataset, making the movie more distinct.\n",
    "   - Example: A movie with unique tags like \"007\" or \"Commander\" may have a higher score than one with generic tags like \"Drama\" or \"Action.\"\n",
    "\n",
    "2. **Low Relevance Score:**\n",
    "   - The movie is associated with common tags or tags with low relevance.\n",
    "   - The movie might not have a strong identity defined by its genome tags.\n",
    "   - Example: A movie tagged with common terms like \"Drama\" and \"Action\" might have a lower score than one tagged with niche terms like \"Sci-Fi Thriller.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the list of all tags for all movies\n",
    "all_tags = [tag for tags in movies_df['10_most_relevant_genome_tags'] for tag, count in tags]\n",
    "\n",
    "# Count occurrences of each tag\n",
    "tag_counts = Counter(all_tags)\n",
    "\n",
    "# Total number of movies\n",
    "total_movies = len(movies_df)\n",
    "\n",
    "# Compute the global weight for each tag (inverse tag frequency)\n",
    "global_weights = {tag: np.log(total_movies / count) for tag, count in tag_counts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_relevance_score(tags, global_weights):\n",
    "    score = 0\n",
    "    for tag, relevance in tags:\n",
    "        global_weight = global_weights.get(tag, 0)\n",
    "        score += relevance * global_weight\n",
    "    return score\n",
    "\n",
    "# Compute the relevance score for each movie\n",
    "movies_df['relevance_score_for_genome_tags'] = movies_df['10_most_relevant_genome_tags'].apply(\n",
    "    lambda tags: compute_relevance_score(tags, global_weights)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the task is to make 4 additional features. Namely `rating_counts` depicting the number of ratings given by users for each movie id, `genere_diversity`: depicting number of generes associated to each movie id, and `user_tag_diversity`: depicting range of user-defined tags associated to each movie id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional features\n",
    "\n",
    "# 6th Rating count\n",
    "rating_count = ratings_df.groupby(\"movieId\")[\"rating\"].count().rename(\"rating_count\")\n",
    "movies_df = movies_df.merge(rating_count, on=\"movieId\")\n",
    "\n",
    "# 7th Genre diversity\n",
    "movies_df[\"genre_diversity\"] = movies_df[list(genre_list)].sum(axis=1)\n",
    "\n",
    "# 8th User-defined Tag diversity\n",
    "user_tag_diversity = tags_df.groupby(\"movieId\")[\"tag\"].nunique().rename(\"tag_diversity\")\n",
    "movies_df = movies_df.merge(user_tag_diversity, on=\"movieId\")\n",
    "\n",
    "movies_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of the dataset: {movies_df.shape}\")\n",
    "print(f\"Missing values: {movies_df.isna().sum()}\")\n",
    "movies_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's save the dataset\n",
    "movies_df.to_csv(\"movies_data.csv\")\n",
    "\n",
    "movies_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Question** : If you have accurately identified and applied the methods for representing the features, you should have more than eight features! How could this happen? Take a moment to think about it.\n",
    "\n",
    "**Answer** : Genre column was made into one hot encoding, making many features!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Choose your features (variables)!\n",
    "\n",
    "With multiple features available for the movies, you need to consider the following two questions: 1. Should you normalize the data or leave it as is? 2. Should you include all these features, or can you reduce the dimensionality of the data?  \n",
    "\n",
    "1. What is the importance of normalizing the data in your analysis, and how does it impact the effectiveness of the clustering algorithms you plan to use?\n",
    "2. If you find that normalizing the values is beneficial, please proceed to normalize the data. To simplify this task, refer to the scikit-learn package for tools and functions that facilitate data normalization.\n",
    "3. Could you provide some insights on dimensionality reduction? What techniques would be effective for reducing the number of features in the dataset, and why might this be beneficial for the analysis?\n",
    "4. If you believe dimensionality reduction would be advantageous, please select a method to reduce the dimensionality of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "1. Many learning algorithms assume that all features are normalised to some certain range with a certain standard deviation, for example mean of 0 and standard deviation of 1. For example, Principal Component Analysis (PCA) **requires** the variables to be normalized. This is because PCA is sensitive to the variances of the original variables. If the variables are on different scales, those with larger scales will dominate the principal components, which can lead to misleading results.  \n",
    "    \n",
    "    Also, we need normalization for clustering. Normalisation ensures that all features contribute equally to the distance calculations used in clustering algorithms. Without normalization, features with larger scales can dominate the distance metrics, leading to biased clustering results.\n",
    "    \n",
    "    Similarly, K-Means rely on distance metrics (e.g., Euclidean distance) to group similar data points. Normalizing the data ensures that these distance metrics are meaningful and not skewed by features with different scales.\n",
    "\n",
    "2. As outlined above, normalizing the real numbers to a certain is crucial to some learning algorithms. Thus, we will proceed with the `StandardScaler()` function to normalise our data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.drop(columns=[\"genres\", \"title\", \"movieId\", \"top_10_user_defined_tags\", \"10_most_relevant_genome_tags\"], inplace=True)\n",
    "\n",
    "# Now, we will normalise the data using StandardScaler from sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "columns_to_scale = ['ratings_avg','relevance_score_for_tags','relevance_score_for_genome_tags','rating_count','genre_diversity','tag_diversity']\n",
    "\n",
    "movies_df[columns_to_scale] = scaler.fit_transform(movies_df[columns_to_scale])\n",
    "\n",
    "movies_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "3. Could you provide some insights on dimensionality reduction? What techniques would be effective for reducing the number of features in the dataset, and why might this be beneficial for the analysis?\n",
    "\n",
    "Dimensionality reduction refers to techniques that reduce the number of features in a dataset in such a way that the reduced dataset can still capture the essential information contained in the original dataset. Some techniques that can be used for dimensionality reduction include:\n",
    "\n",
    "- **Principal Component Analysis (PCA)**: PCA is a linear dimensionality reduction technique that aims to find the directions (principal components) along which the variance of the data is maximized. By projecting the data onto a lower-dimensional subspace spanned by the principal components, PCA can reduce the dimensionality of the data while retaining most of the variance.\n",
    "- **Singular Value Decomposition (SVD)**: SVD is a matrix factorization technique that can be used for dimensionality reduction. By decomposing the data matrix into three matrices, SVD can capture the underlying structure of the data and reduce its dimensionality.\n",
    "- **Linear Discriminant Analysis (LDA)**: LDA is a supervised dimensionality reduction technique that aims to find the directions that maximize the separation between different classes in the data. By projecting the data onto the directions that maximize the class separation, LDA can reduce the dimensionality of the data while preserving the class structure.\n",
    "\n",
    "Dimensionality reduction can be beneficial for the analysis for several reasons, for example:\n",
    "- **Reduced computational complexity**: By reducing the number of features in the dataset, dimensionality reduction can lead to faster training and inference times for machine learning models.\n",
    "- **Noise reduction**: Dimensionality reduction can help remove noisy features from the dataset, which can improve the generalization performance of machine learning models.\n",
    "- **Visualization**: Dimensionality reduction techniques such as PCA can be used to visualize high-dimensional data in a lower-dimensional space, making it easier to interpret and analyze the data.\n",
    "\n",
    "4. If you believe dimensionality reduction would be advantageous, please select a method to reduce the dimensionality of the data.\n",
    "\n",
    "We will use PCA for dimensionality reduction! PCA works by transforming the original features into a set of orthogonal components that capture the variance in the data. The key idea behind PCA is to identify the directions (principal components) in the feature space where the data varies the most. These components are ordered in decreasing order of the variance they explain, with the first principal component explaining the most variance. If the reduction in the number of features is significant, we will incorporate the PCA. Else, we will stick with our original dataset.\n",
    "\n",
    "NB: Will will only perform PCA on numeric columns that are not one hot encoded, because PCA assumes that the relationships between features are linear. However, one-hot encoding creates features that are not linearly related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for PCA\n",
    "pca_data = movies_df[columns_to_scale]\n",
    "\n",
    "# Lets perform the PCA\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = PCA(n_components=len(pca_data.columns))\n",
    "pca.fit(pca_data)\n",
    "\n",
    "# Plotting the explained variance ratio\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), np.cumsum(pca.explained_variance_ratio_), marker='o', linestyle='--')\n",
    "plt.title(\"Explained Variance Ratio by Components\")\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.xticks(range(1, len(pca.explained_variance_ratio_) + 1))\n",
    "plt.axhline(0.90, color='red', linestyle='--', label='90 percent Explained Variance')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we need more than 4 components (i.e. 5 components) to capture atleast 90% of the variance in the data, the reduction is not that significant from our original 6 features. However, we will still use the PCA data because of the added benefits of reduced dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we will make use of 90% explained variance ratio to reduce the number of components\n",
    "\n",
    "pca = PCA(n_components=0.90)\n",
    "pca.fit(pca_data)\n",
    "\n",
    "pca_data = pca.transform(pca_data)\n",
    "\n",
    "pca_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_cols = [col for col in movies_df.columns if col not in columns_to_scale]\n",
    "\n",
    "# merge the pca_data with the original dataset\n",
    "\n",
    "pca_df = pd.DataFrame(pca_data, columns=[f\"PC{i+1}\" for i in range(pca_data.shape[1])])\n",
    "movies_df = pd.concat([movies_df[one_hot_cols], pca_df], axis=1)\n",
    "movies_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data for clustering\n",
    "columns_to_scale = [col for col in movies_df.columns if col.startswith(\"PC\")]\n",
    "scaler = StandardScaler()\n",
    "movies_df[columns_to_scale] = scaler.fit_transform(movies_df[columns_to_scale])\n",
    "\n",
    "movies_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "movies_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.3 Clustering.\n",
    "\n",
    "Now that you have prepared the data, you can create the clusters.\n",
    "\n",
    "Q: How can you determine the optimal number of clusters for your data? Please use at least two methods and provide their results.  \n",
    "\n",
    "A: The two most common methods for choosing the number of clusters in a clustering problem are: The elbow method and the silhouette score method.  \n",
    "\n",
    "**Elbow Method**: The elbow method is a heuristic used to determine the optimal number of clusters in a dataset. The method involves plotting the explained variation as a function of the number of clusters, and the \"elbow\" point is the point at which the rate of decrease sharply changes. This method is based on the principle that the optimal number of clusters is the point at which the explained variation begins to decrease at a slower rate. It uses the sum of squared distances between data points and their assigned clusters' centroids. The sum of squared distances is calculated for each number of clusters, and the optimal number of clusters is chosen based on the \"elbow\" point in the plot of the sum of squared distances.\n",
    "\n",
    "To interpret the elbow method, we look for the point where the explained variation begins to decrease at a slower rate, forming an \"elbow\" shape in the plot. This point indicates the optimal number of clusters for the dataset.\n",
    "\n",
    "**Silhouette Score Method**: The silhouette score is a measure of how similar an object is to its cluster compared to other clusters. The silhouette score ranges from -1 to 1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters. The silhouette score is calculated for each number of clusters, and the optimal number of clusters is chosen based on the highest silhouette score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "# Instantiate the clustering model and visualizer\n",
    "model = KMeans()\n",
    "visualizer = KElbowVisualizer(model, k=(3,10), timings=False)\n",
    "visualizer.fit(movies_df) # Fit the data to the visualizer\n",
    "visualizer.show() # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans()\n",
    "visualizer = KElbowVisualizer(\n",
    "model, k=(4,10), metric='silhouette', timings=False)\n",
    "visualizer.fit(movies_df) # Fit the data to the visualizer\n",
    "visualizer.show() # Finalize and render the figue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the elbow and silhouette score suggest that the optimal number of clusters is 5 or 6!\n",
    "\n",
    "---\n",
    "\n",
    "2. Implement the K-means clustering algorithm (not K-means++) through MapReduce. We request that you develop the algorithm from scratch based on what you've learned in class and run the algorithm on your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "# Add an index to the DataFrame (PointID) and convert to RDD\n",
    "data_rdd = sc.parallelize(movies_df.reset_index().values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = MyKMeans(k=6, num_iterations=10, tolerance=1e-4)\n",
    "# Fit the model\n",
    "cluster_assignments = kmeans.fit(data_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_assignments.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_assignments.groupby(\"ClusterID\")[\"PointID\"].apply(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the output above, one can see the cluster assignments for each point in the dataset. The CluserID (as an index in the output) represents the cluster number, and the list represents the points (movies) assigned to that cluster.\n",
    "\n",
    "3. Implement the K-means++ algorithm from scratch and apply it to your data. Do you notice any differences between the results obtained using random initialization and those achieved with K-means++? Please explain your observations and discuss why these differences might occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_plus = KMeansPlusPlus(k=6, num_iterations=10, tolerance=1e-4)\n",
    "\n",
    "# Fit the model\n",
    "cluster_assignments = kmeans_plus.fit(data_rdd)\n",
    "\n",
    "print(cluster_assignments.groupby(\"ClusterID\")[\"PointID\"].apply(list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> We can see that there is a better convergence with Kmeans++ \n",
    "\n",
    "\n",
    "4. Ask an LLM (ChatGPT, Claude Al, Gemini, Perplexity, etc.) to recommend another clustering algorithm. Use that LLM to describe the workings of the algorithm, as well as its advantages and disadvantages compared to K-means and K-means++. Additionally, ask to implement the algorithm for you or utilize an existing version from a package. Apply that algorithm to your data and explain any differences you observe in the results compared to those obtained previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Perform DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "dbscan_labels = dbscan.fit_predict(movies_df)\n",
    "\n",
    "# Analyze results\n",
    "unique_clusters = set(dbscan_labels)\n",
    "print(f\"Number of clusters found: {len(unique_clusters) - (1 if -1 in unique_clusters else 0)}\")\n",
    "print(f\"Number of noise points: {list(dbscan_labels).count(-1)}\")\n",
    "\n",
    "# Compare with K-means cluster assignments\n",
    "comparison_df = pd.DataFrame({\n",
    "    'K-means_Cluster': cluster_assignments['ClusterID'],\n",
    "    'DBSCAN_Cluster': dbscan_labels\n",
    "})\n",
    "print(\"\\nCluster Distribution Comparison:\")\n",
    "print(comparison_df['DBSCAN_Cluster'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "\n",
    "# Perform Gaussian Mixture Clustering\n",
    "gmm = GaussianMixture(n_components=6, random_state=42)\n",
    "gmm_labels = gmm.fit_predict(movies_df)\n",
    "\n",
    "# Analyze results\n",
    "cluster_distribution = pd.Series(gmm_labels).value_counts()\n",
    "print(\"Cluster Distribution:\")\n",
    "print(cluster_distribution)\n",
    "\n",
    "# Compare with previous clustering methods\n",
    "comparison_df = pd.DataFrame({\n",
    "    'K-means_Cluster': cluster_assignments['ClusterID'],\n",
    "    'DBSCAN_Cluster': dbscan_labels,\n",
    "    'GMM_Cluster': gmm_labels\n",
    "})\n",
    "\n",
    "print(\"\\nCluster Agreement:\")\n",
    "print(pd.crosstab(comparison_df['K-means_Cluster'], comparison_df['GMM_Cluster']))\n",
    "\n",
    "# Compute BIC and log-likelihood to assess model fit\n",
    "print(\"\\nModel Metrics:\")\n",
    "print(f\"Log-Likelihood: {gmm.score(movies_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <strong> 2.4 Best Algorithm\n",
    "\n",
    "Clustering helps identify natural groupings within data, but no single algorithm works best for every dataset. In this section, you’ll learn how to choose the most suitable clustering method based on your data’s unique characteristics. By analyzing patterns and comparing results, you’ll uncover which algorithm provides the most meaningful insights and clusters.\n",
    "\n",
    "2.4.1. Set the number of clusters to the optimal number k based on any of the methods previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5 #optimal k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4.2. Select three distinct metrics to assess the quality of the clusters. Describe each metric in detail, including the specific aspects they evaluate to determine the effectiveness of the clustering model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Clustering metrics we chose\n",
    "\n",
    "### **1. Silhouette Score**\n",
    "\n",
    "The **Silhouette Score** evaluates how well each data point fits within its assigned cluster compared to other clusters. It is defined as:\n",
    "\n",
    "$\n",
    "s(i) = \\frac{b(i) - a(i)}{\\max(a(i), b(i))}\n",
    "$\n",
    "\n",
    "Where:\n",
    "- $ a(i) $: The average distance from point $ i $ to all other points in the same cluster.\n",
    "- $ b(i) $: The average distance from point $ i $ to all points in the nearest cluster (not including its own).\n",
    "\n",
    "The Silhouette Score ranges from $-1$ to $1$:\n",
    "- $ s(i) \\approx 1 $: The point is well-clustered.\n",
    "- $ s(i) \\approx 0 $: The point lies on the boundary between clusters.\n",
    "- $ s(i) \\approx -1 $: The point is likely misclassified.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Davies-Bouldin Index**\n",
    "\n",
    "The **Davies-Bouldin Index** measures the average similarity ratio of each cluster with its most similar cluster. It is defined as:\n",
    "\n",
    "$\n",
    "DB = \\frac{1}{k} \\sum_{i=1}^{k} \\max_{j \\neq i} \\left( \\frac{\\sigma_i + \\sigma_j}{d(c_i, c_j)} \\right)\n",
    "$\n",
    "\n",
    "Where:\n",
    "- $ k $: The number of clusters.\n",
    "- $ \\sigma_i $: The average distance between points in cluster $ i $ and their cluster centroid.\n",
    "- $ d(c_i, c_j) $: The Euclidean distance between centroids $ c_i $ and $ c_j $.\n",
    "\n",
    "Lower values of $ DB $ indicate better clustering (more compact and well-separated clusters).\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Calinski-Harabasz Index**\n",
    "\n",
    "The **Calinski-Harabasz Index**, also known as the Variance Ratio Criterion, measures the ratio of between-cluster dispersion to within-cluster dispersion. It is defined as:\n",
    "\n",
    "$\n",
    "CH = \\frac{\\text{Tr}(B_k)}{\\text{Tr}(W_k)} \\cdot \\frac{N - k}{k - 1}\n",
    "$\n",
    "\n",
    "Where:\n",
    "- $ N $: The total number of data points.\n",
    "- $ k $: The number of clusters.\n",
    "- $ \\text{Tr}(B_k) $: Trace of the between-cluster dispersion matrix.\n",
    "- $ \\text{Tr}(W_k) $: Trace of the within-cluster dispersion matrix.\n",
    "\n",
    "Higher values of $ CH $ indicate better clustering (higher separation and cohesion).\n",
    "\n",
    "---\n",
    "\n",
    "### Summary Table\n",
    "\n",
    "| Metric                  | Ideal Value    | Interpretation                                          |\n",
    "|-------------------------|----------------|---------------------------------------------------------|\n",
    "| **Silhouette Score**    | Close to $1$ | Well-defined, compact, and separated clusters.         |\n",
    "| **Davies-Bouldin Index**| Close to $0$ | Compact clusters with high separation.                 |\n",
    "| **Calinski-Harabasz**   | Higher values  | Higher separation between clusters and compact within. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "X = movies_df\n",
    "# Initialize clustering algorithms\n",
    "clustering_algorithms = {\n",
    "    \"Gaussian Mixture Model\": GaussianMixture(n_components=k, random_state=42), # <- to change into our kmean\n",
    "    \"KMeans\": KMeans(n_clusters=k, random_state=42),\n",
    "    \"DBSCAN\": DBSCAN(eps=0.5, min_samples=10)\n",
    "}\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "for name, model in clustering_algorithms.items():\n",
    "    # Fit the model and predict cluster labels\n",
    "    if name == \"DBSCAN\":\n",
    "        labels = model.fit_predict(X)\n",
    "    else:\n",
    "        labels = model.fit(X).predict(X)\n",
    "\n",
    "    # Calculate metrics if clusters are defined (DBSCAN might label noise as -1)\n",
    "    if len(set(labels)) > 1:\n",
    "        silhouette = silhouette_score(X, labels)\n",
    "        davies_bouldin = davies_bouldin_score(X, labels)\n",
    "        calinski_harabasz = calinski_harabasz_score(X, labels)\n",
    "    else:\n",
    "        silhouette = None\n",
    "        davies_bouldin = None\n",
    "        calinski_harabasz = None\n",
    "\n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        \"Silhouette Score\": silhouette,\n",
    "        \"Davies-Bouldin Index\": davies_bouldin,\n",
    "        \"Calinski-Harabasz Index\": calinski_harabasz\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the evaluation results\n",
    "for algo, metrics in results.items():\n",
    "    print(f\"Results for {algo}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value if value is not None else 'N/A'}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **Results Analysis**\n",
    "\n",
    "| Metric                  | GMM                | KMeans             | DBSCAN            | Interpretation                                                                                     |\n",
    "|-------------------------|--------------------|--------------------|-------------------|---------------------------------------------------------------------------------------------------|\n",
    "| **Silhouette Score**    | $0.0726 $      | $0.1915 $       | $-0.1233 $     | Higher is better. KMeans has the best result, indicating better-defined clusters. DBSCAN struggles significantly. |\n",
    "| **Davies-Bouldin Index**| $2.3005 $      | $1.3512 $       | $1.8898 $      | Lower is better. KMeans performs the best, showing compact and well-separated clusters.           |\n",
    "| **Calinski-Harabasz**   | $1063.9338 $   | $1937.7045 $    | $164.3101 $    | Higher is better. KMeans significantly outperforms both GMM and DBSCAN in terms of cluster quality. |\n",
    "\n",
    "---\n",
    "\n",
    "### **Observations**\n",
    "\n",
    "1. **Gaussian Mixture Model (GMM)**:\n",
    "   - The **Silhouette Score** is positive but very low, indicating weak cluster definition.\n",
    "   - The **Davies-Bouldin Index** is relatively high, meaning the clusters are not well-separated.\n",
    "   - The **Calinski-Harabasz Index** is decent but falls short compared to KMeans.\n",
    "   - GMM struggles to form distinct clusters effectively for this dataset.\n",
    "\n",
    "2. **KMeans**:\n",
    "   - The best-performing algorithm across all metrics.\n",
    "   - The **Silhouette Score** is highest, indicating well-separated clusters.\n",
    "   - The **Davies-Bouldin Index** is the lowest, showing compact clusters.\n",
    "   - The **Calinski-Harabasz Index** is the highest, reflecting strong cohesion and separation.\n",
    "   - KMeans is the most suitable algorithm for this dataset.\n",
    "\n",
    "3. **DBSCAN**:\n",
    "   - The **Silhouette Score** is negative, suggesting overlapping clusters or poor clustering.\n",
    "   - The **Davies-Bouldin Index** is better than GMM but worse than KMeans.\n",
    "   - The **Calinski-Harabasz Index** is extremely low, likely due to poor performance in separating clusters or treating many points as noise.\n",
    "   - DBSCAN is unsuitable for this dataset, possibly because the clusters are not well-defined.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) \n",
    "## **K-means Clustering: Understanding and Implementation**\n",
    "\n",
    "### **What is K-means Clustering?**\n",
    "\n",
    "K-means is a popular unsupervised machine learning algorithm used for **clustering**. It partitions a dataset into k clusters by iteratively refining the cluster centers (centroids). The goal of the algorithm is to minimize the **intra-cluster distance**, which is the sum of squared distances between each data point and its closest centroid. \n",
    "\n",
    "### **How does K-means work?**\n",
    "1. **Initialization**:\n",
    "   - Select k, the number of clusters with the help of the \"elbow method\".\n",
    "   - Randomly initialize k centroids in the feature space.\n",
    "\n",
    "2. **Assignment**:\n",
    "   - Assign each data point to the nearest centroid based on a distance metric.\n",
    "\n",
    "3. **Update**:\n",
    "   - Compute the new centroids as the mean of all points assigned to each cluster.\n",
    "\n",
    "4. **Repeat**:\n",
    "   - Reassign data points to the nearest centroid and update centroids until convergence or the maximum number of iterations is reached.\n",
    "\n",
    "\n",
    "### **What will we do in this part?**\n",
    "\n",
    "1. **Select Features**: We will choose two features from the movie dataset that can be represented as a 2D plot.\n",
    "2. **Choose K**: Choose k using the \"Elbow Method\" with the help of a graphical representation.\n",
    "3. **K-means Algorithm**: Apply K-means clustering (the one developed in the second question) to the selected features.\n",
    "4. **Visualize Clustering Progress**: Create a 2D plot to track the progression of clusters at each iteration.\n",
    "5. **Final Clusters**: Display the final clusters and centroids after convergence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Feature Selection**\n",
    "\n",
    "### **Chosen Variables**\n",
    "1. **Average Rating**: This variable represents the average rating given to a movie. It provides insight into how well a movie is received by users.\n",
    "2. **Number of Reviews**: This variable represents the total number of reviews a movie has received. It indicates the popularity or engagement level of a movie.\n",
    "\n",
    "### **Reason for Selection**\n",
    "The two chosen variables were selected because they are:\n",
    "- **Numerical**: Both variables are continuous and suitable for clustering using K-means, which relies on distance metrics.\n",
    "- **Visually Distinctive**: Average ratings and the number of reviews capture different dimensions of user behavior, creating meaningful separations in the data.\n",
    "- **Meaningful Clusters**: Combining popularity (number of reviews) with quality (average rating) is expected to result in clusters that group movies into categories such as \"highly rated and popular\" or \"low-rated and niche.\"\n",
    "\n",
    "By selecting these variables, we aim to create a 2D visualization that effectively demonstrates the progression of clusters across iterations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(\"/kaggle/input/movielens-20m-dataset/rating.csv\")\n",
    "\n",
    "# Group by movieId to calculate average rating and number of reviews\n",
    "movie_stats = df.groupby(\"movieId\").agg(\n",
    "    average_rating=(\"rating\", \"mean\"),\n",
    "    num_reviews=(\"rating\", \"count\"),\n",
    ").reset_index()\n",
    "\n",
    "# Rename movieId column for consistency\n",
    "movie_stats.rename(columns={\"movieId\": \"idmovie\"}, inplace=True)\n",
    "\n",
    "# Select features\n",
    "features = [\"average_rating\", \"num_reviews\"]\n",
    "X = movie_stats[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Why Standardize Variables?**\n",
    "Before applying K-means, it is important to standardize the chosen variables because:\n",
    "- **Different Scales**: The variables (e.g., `Average Rating` ranging from 0 to 5 and `Number of Reviews` ranging from 0 to thousands) have different scales. Without standardization, the variable with the larger range will dominate the clustering process.\n",
    "- **Equal Contribution**: Standardization ensures that both variables contribute equally to the distance metric used by K-means, making the clustering more balanced and accurate.\n",
    "\n",
    "We standardize the variables by transforming them to have a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the dataset\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Elbow Method**\n",
    "\n",
    "### **What is the Elbow Method?**\n",
    "The Elbow Method is a technique used to determine the optimal number of clusters (\\( k \\)) in a dataset. It involves plotting the **distortion (inertia)**, which is the sum of squared distances between points and their closest centroid, for different values of \\( k \\). The goal is to identify the \"elbow point\" in the graph where the distortion starts to decrease more slowly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow Method to determine optimal number of clusters\n",
    "distortions = []\n",
    "k_values = range(1, 10)\n",
    "\n",
    "for k in k_values:\n",
    "    np.random.seed(42)\n",
    "    initial_indices = np.random.choice(len(X_scaled), size=k, replace=False)\n",
    "    centroids = X_scaled[initial_indices]\n",
    "    \n",
    "    for _ in range(10):  # 10 iterations for consistency\n",
    "        distances = np.linalg.norm(X_scaled[:, np.newaxis] - centroids, axis=2)\n",
    "        labels = np.argmin(distances, axis=1)\n",
    "        centroids = np.array([X_scaled[labels == i].mean(axis=0) for i in range(k)])\n",
    "    \n",
    "    inertia = np.sum([\n",
    "        np.sum((X_scaled[labels == i] - centroids[i])**2) for i in range(k)\n",
    "    ])\n",
    "    distortions.append(inertia)\n",
    "\n",
    "# Plot the Elbow Method\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(k_values, distortions, marker=\"o\", linestyle=\"--\", color=\"b\")\n",
    "plt.title(\"Elbow Method\")\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"Distortion (Inertia)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Chosen Number of Clusters: k = 3**\n",
    "From the Elbow Method plot:\n",
    "1. The distortion decreases significantly as k increases from 1 to 3.\n",
    "2. Beyond k = 3, the distortion decreases at a much slower rate, indicating that adding more clusters does not provide substantial benefits.\n",
    "\n",
    "By choosing k = 3:\n",
    "- We achieve a balance between simplicity (fewer clusters) and clustering accuracy (lower distortion).\n",
    "- The resulting clusters are expected to group movies effectively based on their average ratings and number of reviews.\n",
    "\n",
    "This choice allows us to create meaningful and interpretable clusters for the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Applying the Manual K-means Algorithm**\n",
    "\n",
    "In this step, we apply the **K-means algorithm** developed in **Question 2** to the two selected variables:\n",
    "1. **Average Rating**: The average rating of a movie, representing its quality as perceived by users.\n",
    "2. **Number of Reviews**: The total number of reviews a movie has received, representing its popularity.\n",
    "\n",
    "### **Why Use the Manual K-means Algorithm?**\n",
    "The K-means algorithm implemented in Question 2 provides an opportunity to deeply understand the iterative process of clustering by manually controlling:\n",
    "- The **assignment** of data points to clusters.\n",
    "- The **recalculation** of cluster centroids.\n",
    "- The **convergence criteria**, including the tolerance for centroid movement.\n",
    "\n",
    "This approach ensures transparency and flexibility in clustering, making it easier to visualize and interpret how clusters form and evolve.\n",
    "\n",
    "### **Goal**\n",
    "We will:\n",
    "1. Assign each movie (data point) to one of the three clusters identified earlier using the Elbow Method.\n",
    "2. Track the movement of centroids and changes in cluster assignments over iterations.\n",
    "3. Visualize the progression of clusters and the final clustering result.\n",
    "\n",
    "By applying this manual K-means implementation, we aim to highlight the progression of clustering for these two selected features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize K-means parameters\n",
    "k = 3  # Number of clusters from the Elbow Method\n",
    "num_iterations = 10\n",
    "tolerance = 1e-4\n",
    "\n",
    "# Randomly initialize centroids\n",
    "np.random.seed(42)\n",
    "initial_indices = np.random.choice(len(X_scaled), size=k, replace=False)\n",
    "centroids = X_scaled[initial_indices]\n",
    "\n",
    "# Helper functions\n",
    "def assign_to_centroid(points, centroids):\n",
    "    distances = np.linalg.norm(points[:, np.newaxis] - centroids, axis=2)\n",
    "    return np.argmin(distances, axis=1)\n",
    "\n",
    "def recompute_centroids(points, labels, k):\n",
    "    return np.array([points[labels == i].mean(axis=0) for i in range(k)])\n",
    "\n",
    "# Manual K-means implementation\n",
    "centroids_history = [centroids]\n",
    "labels_history = []\n",
    "\n",
    "for iteration in range(num_iterations):\n",
    "    # Assign points to the nearest centroid\n",
    "    labels = assign_to_centroid(X_scaled, centroids)\n",
    "    labels_history.append(labels)\n",
    "    \n",
    "    # Recompute centroids\n",
    "    new_centroids = recompute_centroids(X_scaled, labels, k)\n",
    "    centroids_history.append(new_centroids)\n",
    "    \n",
    "    # Check for convergence\n",
    "    centroid_shift = np.linalg.norm(new_centroids - centroids)\n",
    "    print(f\"Iteration {iteration + 1}: Centroid shift = {centroid_shift:.4f}\")\n",
    "    if centroid_shift < tolerance:\n",
    "        print(f\"Converged after {iteration + 1} iterations.\")\n",
    "        break\n",
    "    \n",
    "    centroids = new_centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Visualizing the Clustering Progression**\n",
    "\n",
    "### **Steps for Visualization**\n",
    "To better illustrate the clustering process and highlight the changes across iterations, we use the following approach:\n",
    "\n",
    "1. **Iteration 0 (Unclustered Points)**:\n",
    "   - We begin by displaying the distribution of points before applying any clustering.\n",
    "   - All points are shown in a neutral gray color to indicate the absence of clusters.\n",
    "\n",
    "2. **Animated Iterations**:\n",
    "   - Instead of showing separate static plots for each iteration, we create a slow-paced animation.\n",
    "   - The animation highlights:\n",
    "     - The gradual movement of centroids across iterations.\n",
    "     - The evolving cluster assignments with distinct colors for each cluster.\n",
    "\n",
    "3. **Direct Comparison**:\n",
    "   - After the animation, we provide two side-by-side plots:\n",
    "     - **Iteration 1**: The initial clustering result.\n",
    "     - **Final Iteration**: The final clustering result after convergence.\n",
    "   - This comparison helps visualize the radical differences between the initial and final stages of the algorithm.\n",
    "\n",
    "### **Why This Approach?**\n",
    "This method:\n",
    "- Provides a clear understanding of how the clusters and centroids evolve.\n",
    "- Makes it easier to grasp the iterative nature of K-means.\n",
    "- Offers a visual representation of the improvement in clustering quality from start to finish.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Iteration 0\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], color=\"gray\", alpha=0.6, s=50)\n",
    "plt.title(\"Iteration 0: Initial Point Distribution (No Clustering)\")\n",
    "plt.xlabel(\"Standardized Average Rating\")\n",
    "plt.ylabel(\"Standardized Number of Reviews\")\n",
    "plt.show()\n",
    "\n",
    "# Visualize Iteration 1\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=labels_history[1], cmap='viridis', s=50, alpha=0.6)\n",
    "plt.scatter(centroids_history[1][:, 0], centroids_history[1][:, 1], c=\"red\", s=200, marker=\"X\", label=\"Centroids\")\n",
    "plt.title(\"Iteration 1: Initial Clustering\")\n",
    "plt.xlabel(\"Standardized Average Rating\")\n",
    "plt.ylabel(\"Standardized Number of Reviews\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure centroids_history and labels_history are populated from the K-means function\n",
    "\n",
    "# Initialize the plot for animation\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "scatter = ax.scatter(X_scaled[:, 0], X_scaled[:, 1], c=np.zeros(len(X_scaled)), cmap='viridis', s=50)\n",
    "centroids_plot, = ax.plot([], [], 'rX', markersize=10, label='Centroids')\n",
    "ax.set_title(\"Cluster Animation (Manual K-means)\")\n",
    "ax.set_xlabel(\"Standardized Average Rating\")\n",
    "ax.set_ylabel(\"Standardized Number of Reviews\")\n",
    "ax.legend()\n",
    "\n",
    "# Function to update the animation frame by frame\n",
    "def update(frame):\n",
    "    centroids = centroids_history[frame]\n",
    "    labels = labels_history[frame] if frame < len(labels_history) else labels_history[-1]\n",
    "    \n",
    "    # Update scatter plot with the current labels\n",
    "    scatter.set_array(labels)\n",
    "    scatter.set_clim(-1, k - 1)  # Ensure consistent color mapping\n",
    "    \n",
    "    # Update centroids\n",
    "    centroids_plot.set_data(centroids[:, 0], centroids[:, 1])\n",
    "    \n",
    "    ax.set_title(f\"Iteration {frame}: Manual K-means\")\n",
    "    return scatter, centroids_plot\n",
    "\n",
    "# Create the animation\n",
    "anim = FuncAnimation(fig, update, frames=len(centroids_history), interval=1000, blit=False)\n",
    "\n",
    "# Save the animation as a GIF\n",
    "gif_path = \"/kaggle/working/manual_kmeans_animation.gif\"\n",
    "anim.save(gif_path, writer=PillowWriter(fps=1))\n",
    "\n",
    "# Display the animation\n",
    "from IPython.display import Image\n",
    "display(Image(filename=gif_path))\n",
    "\n",
    "# Side-by-side comparison of Iteration 1 and Final Iteration\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Iteration 1\n",
    "axes[0].scatter(X_scaled[:, 0], X_scaled[:, 1], c=labels_history[1], cmap=\"viridis\", s=50, alpha=0.6)\n",
    "axes[0].scatter(centroids_history[1][:, 0], centroids_history[1][:, 1], c=\"red\", s=200, marker=\"X\", label=\"Centroids\")\n",
    "axes[0].set_title(\"Iteration 1: Initial Clustering\")\n",
    "axes[0].set_xlabel(\"Standardized Average Rating\")\n",
    "axes[0].set_ylabel(\"Standardized Number of Reviews\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Final Iteration\n",
    "axes[1].scatter(X_scaled[:, 0], X_scaled[:, 1], c=labels_history[-1], cmap=\"viridis\", s=50, alpha=0.6)\n",
    "axes[1].scatter(centroids_history[-1][:, 0], centroids_history[-1][:, 1], c=\"red\", s=200, marker=\"X\", label=\"Centroids\")\n",
    "axes[1].set_title(\"Final Iteration: Clustered Points\")\n",
    "axes[1].set_xlabel(\"Standardized Average Rating\")\n",
    "axes[1].set_ylabel(\"Standardized Number of Reviews\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a look at **manual_kmeans_animation gif** to see how the clusters change after each iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Algorithmic Question\n",
    "\n",
    "Two brilliant strategists, Arya and Mario, are about to play a game with a sequence of numbers. Arya, as player 1, begins the game, while Mario, player 2, plays 2nd. Their goal is clear: to collect the highest possible score by taking numbers from either end of the sequence, one at a time. They will play in perfect synchronicity, each seeking the advantage.\n",
    "\n",
    "The sequence represented as an array of nums, is laid out in front of them. Arya will start by selecting either the number at the beginning (nums[0]) or the end (nums[nums.length - 1]) of the array, adding that value to her score. This value is then removed from the beginning or the end of nums. Then, it’s Mario’s turn to do the same with the remaining sequence. The game proceeds this way, with each player taking numbers from either end until no numbers are left to claim. The player with the highest score wins.\n",
    "\n",
    "However, if they end in a tie, Arya, as the first to act, will claim victory by default.\n",
    "\n",
    "Arya is now before you, asking for help to predict her chances. She wants to know, with her best possible choices, whether she can guarantee a win, assuming both players play with perfect skill.\n",
    "\n",
    "a) Help Arya by providing a pseudocode for finding an optimal playing strategy, that is, a strategy that maximizes her value. (Hint: Use recursion, assuming that both players play optimally).\n",
    "\n",
    "b) Write a Python program implementing her game strategy. Try different array lengths to test the algorithm.\n",
    "\n",
    "c) Is the algorithm efficient? Prove that it is polynomial and provide an asymptotic time complexity bound, or show that it requires exponential time.\n",
    "\n",
    "d) If the algorithm is exponential, explain how to make it polynomial and provide a pseudocode for it. Recompute the computational complexity of the updated algorithm.\n",
    "\n",
    "e) Implement the algorithm in Python. Compare your result values with the previous algorithm. Also compare the running times.\n",
    "\n",
    "f) Finally, consult LLM (ChatGPT, Claude AI, Gemini, Perplexity, etc.) to craft a third, optimized implementation and analyze its time complexity. Also, explain if the LLM is doing a good job and how you can evaluate whether the suggested solution works properly.\n",
    "\n",
    "Examples\n",
    "\n",
    "Input 1\n",
    "\n",
    "nums = [1, 5, 2]\n",
    "Output 1\n",
    "\n",
    "false\n",
    "Explanation: Arya’s optimal choices still lead her to a lower score than Mario’s, so she cannot guarantee victory.\n",
    "\n",
    "Input 2\n",
    "\n",
    "nums = [1, 5, 233, 7]\n",
    "Output 2\n",
    "\n",
    "true\n",
    "Explanation: Arya, by playing perfectly, can ensure she ends up with the highest score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy: <br>\n",
    "Considering that both players play optimally, when we make a choice we should take into consideration the element we leave uncovered after our choice. So basically we should take into account both elements that hide behind the first and the last elements of the array because they could have a bigger effect on the final score.<br>\n",
    "More precisely to choose the move that maximizes the Arya's advantage, in each turn, we should subtract the opponent's best possible play from our choice and maximize the difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Pseudocode for `game(nums)` Algorithm\n",
    "\n",
    "### Main Function: `game(nums)`\n",
    "1. Create a copy of the input list `nums` to avoid modifying the original.\n",
    "   - `nums = nums[:]`\n",
    "\n",
    "2. Define a helper function `maxDiff(left, right)`:\n",
    "   - **Input**: \n",
    "     - `left`: Index of the first number under consideration.\n",
    "     - `right`: Index of the last number under consideration.\n",
    "   - **Base Case**: If `left > right`, return `0` (no numbers left to choose).\n",
    "   - **Recursive Case**:\n",
    "     - `choose_first = nums[left] - maxDiff(left + 1, right)`  \n",
    "       (Choose the first number and subtract opponent's best response).\n",
    "     - `choose_last = nums[right] - maxDiff(left, right - 1)`  \n",
    "       (Choose the last number and subtract opponent's best response).\n",
    "     - Return `max(choose_first, choose_last)`.\n",
    "\n",
    "3. Initialize two lists to track scores:\n",
    "   - `arya_scores = []` (Arya's scores)\n",
    "   - `mario_scores = []` (Mario's scores)\n",
    "\n",
    "4. Set `turn = \"Arya\"` to denote that Arya starts first.\n",
    "\n",
    "5. **While** `nums` is not empty:\n",
    "   - **If** `turn == \"Arya\"`:\n",
    "     - Use `maxDiff(0, len(nums) - 1)` to determine the optimal choice:\n",
    "       - **If** `maxDiff(1, len(nums) - 1) < 0`,  \n",
    "         Arya picks the first number (`nums.pop(0)`).\n",
    "       - **Else**, Arya picks the last number (`nums.pop()`).\n",
    "     - Append Arya's choice to `arya_scores`.\n",
    "     - Set `turn = \"Mario\"`.\n",
    "   - **Else** (Mario's turn):\n",
    "     - Use similar logic to Arya:\n",
    "       - **If** `maxDiff(1, len(nums) - 1) < 0`,  \n",
    "         Mario picks the first number (`nums.pop(0)`).\n",
    "       - **Else**, Mario picks the last number (`nums.pop()`).\n",
    "     - Append Mario's choice to `mario_scores`.\n",
    "     - Set `turn = \"Arya\"`.\n",
    "\n",
    "6. **End While**\n",
    "\n",
    "7. Calculate the total scores:\n",
    "   - `arya_total = sum(arya_scores)`\n",
    "   - `mario_total = sum(mario_scores)`\n",
    "\n",
    "8. **Return** `arya_total >= mario_total` (True if Arya's score is greater than or equal to Mario's score, False otherwise)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Python Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game(nums):\n",
    "    # Create a copy of the list to avoid modifying the original\n",
    "    nums = nums[:]\n",
    "    \n",
    "    def maxDiff(left, right): #We define function to assist us with making the best choice between left=nums[0] and right=nums[-1].\n",
    "        # Base case: no numbers left\n",
    "        if left > right:\n",
    "            return 0\n",
    "        \n",
    "        # Two possible moves:\n",
    "        # 1. Take the first number and subtract opponent's best response\n",
    "        choose_first = nums[left] - maxDiff(left + 1, right)\n",
    "        \n",
    "        # 2. Take the last number and subtract opponent's best response\n",
    "        choose_last = nums[right] - maxDiff(left, right - 1)\n",
    "        \n",
    "        # Return the maximum score difference possible\n",
    "        return max(choose_first, choose_last)\n",
    "    \n",
    "    arya_scores = []\n",
    "    mario_scores = []\n",
    "    turn = \"Arya\"  # Arya always starts\n",
    "    \n",
    "    while nums:\n",
    "        if turn == \"Arya\":\n",
    "            # Use maxDiff to determine the optimal choice\n",
    "            if maxDiff(0, len(nums) - 1) >= 0:\n",
    "                # If first number leads to better outcome\n",
    "                if maxDiff(1, len(nums) - 1) < 0:\n",
    "                    arya_scores.append(nums.pop(0))\n",
    "                else:\n",
    "                    arya_scores.append(nums.pop())\n",
    "            else:\n",
    "                # If last number leads to better outcome\n",
    "                arya_scores.append(nums.pop())\n",
    "            turn = \"Mario\"\n",
    "        else:\n",
    "            # Mario's turn (similar logic)\n",
    "            if maxDiff(0, len(nums) - 1) >= 0:\n",
    "                if maxDiff(1, len(nums) - 1) < 0:\n",
    "                    mario_scores.append(nums.pop(0))\n",
    "                else:\n",
    "                    mario_scores.append(nums.pop())\n",
    "            else:\n",
    "                mario_scores.append(nums.pop())\n",
    "            turn = \"Arya\"\n",
    "    \n",
    "    # Compare the total scores\n",
    "    arya_total = sum(arya_scores)\n",
    "    mario_total = sum(mario_scores)\n",
    "    return arya_total >= mario_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Cases\n",
    "nums1 = [1, 5, 2]\n",
    "nums2 = [1, 5, 233, 7]\n",
    "nums3 = [8, 15, 3, 7]\n",
    "nums4 = [20, 30, 2, 2, 2, 10]\n",
    "nums5 = [4, 1, 100, 5, 10, 20]\n",
    "nums6 = [5, 8, 2, 10, 25, 1, 7, 12, 3, 9]\n",
    "nums7 = [15, 3, 8, 20, 5, 9, 7, 13, 6, 2, 10, 4, 18]\n",
    "\n",
    "print(\"Input:\", nums1, \"-> Output:\", game(nums1))\n",
    "print(\"Input:\", nums2, \"-> Output:\", game(nums2))\n",
    "print(\"Input:\", nums3, \"-> Output:\", game(nums3))\n",
    "print(\"Input:\", nums4, \"-> Output:\", game(nums4))\n",
    "print(\"Input:\", nums5, \"-> Output:\", game(nums5))\n",
    "print(\"Input:\", nums6, \"-> Output:\", game(nums6))\n",
    "print(\"Input:\", nums7, \"-> Output:\", game(nums7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C) Time complexity\n",
    "We begin by proving that time complexity of maxDiff function is exponential and then show that the game function has no big impact on the time complexity of the algorithm.\n",
    "\n",
    "## Idea:\n",
    " The maxDiff function operates in a way that can be visualized as a **binary tree**, where each node represents a state of the game, and the two branches correspond to the two possible choices a player can make (choosing the first number or choosing the last number). The height of the tree is n (the size of the list, as one number is removed at each recursive step). While Total number of nodes in the tree is approximately $2^n$, making the time complexity exponential.\n",
    "\n",
    "## Proof:\n",
    "We will prove by induction that the total number of recursive calls made by maxDiff(left, right) for a list of size $n$ is: $T(n)=2^n\n",
    "-1$<br>\n",
    "**Base Case($n=1$)**<br> For $n=1$ we have a single element, thus the total number of calls is: $T(1)=2^1 -1=1$<br>\n",
    "\n",
    "**Induction:** Assume that for a list of size $k$, the total number of recursive calls made is: $T(k)=2^k -1$<br> Let's prove that the result holds for $k+1$: <br>\n",
    "At the top level, maxDiff(left, right) makes two recursive calls:<br>\n",
    " 1)maxDiff(left + 1, right) for a sublist of size $k$.<br>\n",
    " 2)maxDiff(left, right - 1) for another sublist of size $k$.<br>\n",
    "Using the inductive hypothesis, the number of recursive calls for each of these sublists is: $T(k)=2^k -1$<br>\n",
    "The total number of recursive calls for $k+1$ is: $T(k+1)=1+T(k)+T(k)=1+(2^k -1)+(2^k -1)=2^(k+1) -1$.\n",
    "\n",
    "**Conclusion:**<br>\n",
    "By induction, the total number of recursive calls made by maxDiff for a list of size $n$ is $T(n)=2^n -1$. Hence, the time complexity of maxDiff is exponential, $O(2^n)$.<br>\n",
    "\n",
    "**Incorporation into the game function:**<br>\n",
    "-The $while$ loop iterates $n$ times, in each iteration $maxDiff(0, len(nums) - 1)$ is called multiple times.<br>\n",
    "-If maxDiff itself takes $O(2^n)$, and the loop calls it a constant number of times per iteration, the game function ends up performing $O(n 2^n)$ operations.<br>\n",
    "-Since $2^n$ dominates $n$, the overall time complexity of the game function remains exponential: $O(2^n)$.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D)Let's make it polynomial.\n",
    "To make the algorithm polynomial in time complexity, we need to eliminate the exponential recursion of the maxDiff function. To do so we can use momoization to store the results of previously computed subproblems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudocode for Memoization Method (Dinamic Programming) in `game(nums)` Algorithm\n",
    "\n",
    "### Main Function: `game(nums)`\n",
    "1. Get length of input list `n ← length(nums)`\n",
    "\n",
    "2. Create memoization table `dp`:\n",
    "  - 2D array of size `n × n`\n",
    "  - Initialized with `None`\n",
    "\n",
    "3. Define helper function `maxDiff(left, right)`:\n",
    "  - **Base Case**: If `left > right`, return `0`\n",
    "  - **Memoization Check**: If `dp[left][right]` is not `None`, return memoized value\n",
    "  - **Recursive Choices**:\n",
    "    - `choose_first ← nums[left] - maxDiff(left + 1, right)`\n",
    "    - `choose_last ← nums[right] - maxDiff(left, right - 1)`\n",
    "  - Memoize result: `dp[left][right] ← max(choose_first, choose_last)`\n",
    "  - Return `dp[left][right]`\n",
    "\n",
    "4. Initialize game variables:\n",
    "  - `arya_scores ← []`\n",
    "  - `mario_scores ← []`\n",
    "  - `turn ← \"Arya\"`\n",
    "  - `left ← 0`\n",
    "  - `right ← n - 1`\n",
    "\n",
    "5. **While** `left ≤ right`:\n",
    "  - **If** `turn == \"Arya\"`:\n",
    "    - **If** `maxDiff(left, right) ≥ 0`:\n",
    "      - **If** `maxDiff(left + 1, right) < 0`:\n",
    "        - Append `nums[left]` to `arya_scores`\n",
    "        - Increment `left`\n",
    "      - **Else**:\n",
    "        - Append `nums[right]` to `arya_scores`\n",
    "        - Decrement `right`\n",
    "    - **Else**:\n",
    "      - Append `nums[right]` to `arya_scores`\n",
    "      - Decrement `right`\n",
    "    - Set `turn ← \"Mario\"`\n",
    "\n",
    "  - **Else** (Mario's turn):\n",
    "    - Use similar logic to Arya's turn\n",
    "    - Set `turn ← \"Arya\"`\n",
    "\n",
    "6. Calculate total scores:\n",
    "  - `arya_total ← sum(arya_scores)`\n",
    "  - `mario_total ← sum(mario_scores)`\n",
    "\n",
    "7. **Return** `arya_total ≥ mario_total`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Complexity of the updated version\n",
    "\n",
    "Let's consider the effect that memoization has on $maxDiff$ function.<br>\n",
    "With memoization, the results for each (left, right) pair are stored in a table $dp$ of sixe $n$ x $n$, so each unique subproblem is solved at most once.<br>\n",
    "Since left and right can take $O(n^2)$ unique pairs and each pair is solved in $O(1)$ time, the total complexity of $maxDiff$ now is $O(n^2)$.<br>\n",
    "\n",
    "Consider now the game simulation loop that runs until all numbers in the list are picked.<br>\n",
    "The loop iterates $O(n)$ times (since either left or right is incremented or decremented in each iteration).<br>\n",
    "For each iteration, the optimal move for Arya or Mario is determined by calling maxDiff and comparing the results. Since memoization ensures that these calls are $O(1)$ , the per-iteration cost is $O(1)$.<br>\n",
    "\n",
    "Thus, the time complexity of the simulation loop is $O(n)$.<br>\n",
    "\n",
    "**Conclusion**:<br>\n",
    "\n",
    "1)maxDiff computes all $O(n^2)$ subproblems.<br>\n",
    "2)The game simulation runs in $O(n)$, with constant-time lookups in the memoization table.<br>\n",
    "\n",
    "Combining these, the overall time complexity of the algorithm is $O(n^2)$.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E) Python Code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game(nums):\n",
    "    n = len(nums)\n",
    "    # Memoization table\n",
    "    dp = [[None] * n for i in range(n)]\n",
    "\n",
    "    def maxDiff(left, right):\n",
    "        # Base case: no numbers left\n",
    "        if left > right:\n",
    "            return 0\n",
    "        \n",
    "        # Check memoized result\n",
    "        if dp[left][right] is not None:\n",
    "            return dp[left][right]\n",
    "        \n",
    "        # Two possible moves\n",
    "        choose_first = nums[left] - maxDiff(left + 1, right)\n",
    "        choose_last = nums[right] - maxDiff(left, right - 1)\n",
    "        \n",
    "        # Memoize and return best choice\n",
    "        dp[left][right] = max(choose_first, choose_last)\n",
    "        return dp[left][right]\n",
    "\n",
    "    # Game simulation\n",
    "    arya_scores = []\n",
    "    mario_scores = []\n",
    "    turn = \"Arya\"\n",
    "    left, right = 0, n - 1\n",
    "\n",
    "    while left <= right:\n",
    "        if turn == \"Arya\":\n",
    "            # Arya's optimal choice logic\n",
    "            if maxDiff(left, right) >= 0:\n",
    "                if maxDiff(left + 1, right) < 0:\n",
    "                    arya_scores.append(nums[left])\n",
    "                    left += 1\n",
    "                else:\n",
    "                    arya_scores.append(nums[right])\n",
    "                    right -= 1\n",
    "            else:\n",
    "                arya_scores.append(nums[right])\n",
    "                right -= 1\n",
    "            turn = \"Mario\"\n",
    "        else:\n",
    "            # Mario's optimal choice logic\n",
    "            if maxDiff(left, right) >= 0:\n",
    "                if maxDiff(left + 1, right) < 0:\n",
    "                    mario_scores.append(nums[left])\n",
    "                    left += 1\n",
    "                else:\n",
    "                    mario_scores.append(nums[right])\n",
    "                    right -= 1\n",
    "            else:\n",
    "                mario_scores.append(nums[right])\n",
    "                right -= 1\n",
    "            turn = \"Arya\"\n",
    "\n",
    "    # Calculate and return result\n",
    "    return sum(arya_scores) >= sum(mario_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Cases\n",
    "nums1 = [1, 5, 2]\n",
    "nums2 = [1, 5, 233, 7]\n",
    "nums3 = [8, 15, 3, 7]\n",
    "nums4 = [20, 30, 2, 2, 2, 10]\n",
    "nums5 = [4, 1, 100, 5, 10, 20]\n",
    "nums6 = [5, 8, 2, 10, 25, 1, 7, 12, 3, 9]\n",
    "nums7 = [15, 3, 8, 20, 5, 9, 7, 13, 6, 2, 10, 4, 18]\n",
    "\n",
    "print(\"Input:\", nums1, \"-> Output:\", game(nums1))\n",
    "print(\"Input:\", nums2, \"-> Output:\", game(nums2))\n",
    "print(\"Input:\", nums3, \"-> Output:\", game(nums3))\n",
    "print(\"Input:\", nums4, \"-> Output:\", game(nums4))\n",
    "print(\"Input:\", nums5, \"-> Output:\", game(nums5))\n",
    "print(\"Input:\", nums6, \"-> Output:\", game(nums6))\n",
    "print(\"Input:\", nums7, \"-> Output:\", game(nums7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F) Ask LLM and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game(nums):\n",
    "    n = len(nums)\n",
    "    \n",
    "    # Step 1: Create the DP table\n",
    "    dp = [[0] * n for _ in range(n)]\n",
    "    \n",
    "    # Step 2: Fill the DP table iteratively\n",
    "    for length in range(1, n + 1):  # Length of subarray\n",
    "        for left in range(n - length + 1):\n",
    "            right = left + length - 1\n",
    "            if left == right:  # Single element case\n",
    "                dp[left][right] = nums[left]\n",
    "            else:\n",
    "                dp[left][right] = max(\n",
    "                    nums[left] - dp[left + 1][right],  # Pick left\n",
    "                    nums[right] - dp[left][right - 1]  # Pick right\n",
    "                )\n",
    "    \n",
    "    # Step 3: Initialize pointers and scores\n",
    "    left, right = 0, n - 1\n",
    "    arya_score, mario_score = 0, 0\n",
    "    arya_turn = True  # Boolean flag for turns\n",
    "\n",
    "    # Step 4: Simulate the game using the DP table\n",
    "    while left <= right:\n",
    "        if dp[left][right] >= 0:  # Optimal move favors the current player\n",
    "            if dp[left + 1][right] <= dp[left][right - 1]:\n",
    "                choice = nums[left]\n",
    "                left += 1\n",
    "            else:\n",
    "                choice = nums[right]\n",
    "                right -= 1\n",
    "        else:  # No positive difference, take the worse option\n",
    "            choice = nums[right]\n",
    "            right -= 1\n",
    "\n",
    "        # Add the choice to the current player's score\n",
    "        if arya_turn:\n",
    "            arya_score += choice\n",
    "        else:\n",
    "            mario_score += choice\n",
    "\n",
    "        # Alternate turns\n",
    "        arya_turn = not arya_turn\n",
    "\n",
    "    # Step 5: Return the result\n",
    "    return arya_score >= mario_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does the LLM do a Good Job?<br>\n",
    "Yes, the LLM offers a solution that is efficient, well-structured, and clearly different from the original implementation. Here's why:<br>\n",
    "\n",
    "-**Optimization:** The suggested solution optimizes the recursive version into a bottom-up dynamic programming approach. This eliminates the overhead of recursive calls and ensures a predictable time complexity of $O(n^2)$.<br>\n",
    "\n",
    "-**Simplicity:** By introducing compact logic for game simulation, the code is easier to follow and debug. For example, the use of a boolean flag (arya_turn) is cleaner and avoids unnecessary string comparisons.<br>\n",
    "\n",
    "-**Space Efficiency:** The solution reduces auxiliary memory usage by directly updating scores without requiring additional lists (arya_scores and mario_scores).\n",
    "Clear Logic for Moves: The code includes a straightforward approach to decide moves using the DP table, ensuring correctness without overcomplicating the decision-making process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
